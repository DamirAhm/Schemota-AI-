# Отчет о классификации стекла

## Информация о датасете
* Размер датасета: 214 образцов, 9 параметров
* Количество классов: 6
* Распределение классов:
  - Класс 2 (building_windows_non_float): 76 образцов
  - Класс 1 (building_windows_float): 70 образцов
  - Класс 7 (headlamps): 29 образцов
  - Класс 3 (vehicle_windows_float): 17 образцов
  - Класс 5 (containers): 13 образцов
  - Класс 6 (tableware): 9 образцов

## Результаты классификации
* Лучшая модель: Random Forest
* Лучшие параметры: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}
* Точность на тестовой выборке: 0.8308

### Отчет о классификации
```
              precision    recall  f1-score   support

           1       0.80      0.95      0.87        21
           2       0.86      0.78      0.82        23
           3       1.00      0.40      0.57         5
           5       0.60      0.75      0.67         4
           6       0.75      1.00      0.86         3
           7       1.00      0.89      0.94         9

    accuracy                           0.83        65
   macro avg       0.83      0.80      0.79        65
weighted avg       0.85      0.83      0.83        65
```

### RAG анализ (ROC кривые)
#### ROC кривые
ROC (Receiver Operating Characteristic) кривые показывают соотношение между True Positive Rate и False Positive Rate для каждого класса:

| Класс | AUC |
|-------|------|
| 1 (building_windows_float) | 0.9345 |
| 2 (building_windows_non_float) | 0.9529 |
| 3 (vehicle_windows_float) | 0.7433 |
| 5 (containers) | 0.9836 |
| 6 (tableware) | 0.9946 |
| 7 (headlamps) | 1.0000 |

#### Что такое Precision и Recall?
**Precision (Точность)** и **Recall (Полнота)** - это метрики, используемые для оценки качества классификации:

* **Precision (Точность)** - это доля правильно предсказанных положительных результатов среди всех предсказанных положительных результатов. Другими словами, это отношение True Positive к сумме True Positive и False Positive. Высокая точность означает, что модель редко ошибается, когда предсказывает положительный класс.

  Precision = TP / (TP + FP)

* **Recall (Полнота)** - это доля правильно предсказанных положительных результатов среди всех фактических положительных результатов. Другими словами, это отношение True Positive к сумме True Positive и False Negative. Высокая полнота означает, что модель обнаруживает большинство положительных случаев.

  Recall = TP / (TP + FN)

* **Компромисс между Precision и Recall**: Обычно существует обратная зависимость между точностью и полнотой. Увеличение точности часто приводит к снижению полноты и наоборот. Выбор между ними зависит от конкретной задачи. Например, в медицинской диагностике может быть важнее иметь высокую полноту, чтобы не пропустить больных пациентов, даже если это приведет к некоторым ложным тревогам.

* **F1-score**: Это гармоническое среднее между точностью и полнотой, которое дает сбалансированную оценку модели, особенно когда классы несбалансированы.

  F1 = 2 * (Precision * Recall) / (Precision + Recall)

В контексте нашей задачи классификации стекла, эти метрики помогают понять, насколько хорошо модель идентифицирует каждый тип стекла и насколько часто она ошибается, относя образцы к неправильному типу.

### Важность признаков
* Al: 0.1576
* Mg: 0.1532
* Ca: 0.1364
* RI: 0.1331
* Na: 0.1204
* Si: 0.0930
* K: 0.0924
* Ba: 0.0713
* Fe: 0.0425

### Сравнение моделей
* Random Forest: 0.7786 (+/- 0.0148)
* SVM: 0.6772 (+/- 0.0584)
* KNN: 0.6310 (+/- 0.0457)

## Выводы
1. Наиболее важными признаками для классификации типов стекла являются: Al, Mg, Ca
2. Модель Random Forest показала наилучшие результаты среди рассмотренных алгоритмов
3. Точность классификации составляет около 0.83, что является хорошим результатом для данной задачи
4. Некоторые классы классифицируются лучше других, что может быть связано с неравномерным распределением классов в датасете
5. Анализ ROC кривых показывает, что модель имеет различную эффективность для разных классов
6. Для улучшения результатов можно использовать методы балансировки классов или ансамблевые методы
